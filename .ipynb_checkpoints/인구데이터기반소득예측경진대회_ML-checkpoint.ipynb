{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70d77dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    #age\n",
    "    bins = np.linspace(df['age'].min(), df['age'].max(), 10)\n",
    "    df['age'] = np.digitize(df['age'], bins)\n",
    "    \n",
    "    #fnlwgt\n",
    "    df['fnlwgt'] = np.log1p(df['fnlwgt'])\n",
    "    \n",
    "    #capital.gain\n",
    "    \n",
    "    #capital.loss\n",
    "    \n",
    "    #hours.per.week\n",
    "    \n",
    "    #education.num\n",
    "    df.drop(['education.num'], axis=1)\n",
    "    \n",
    "    #education\n",
    "    \n",
    "    \n",
    "    #marital.status\n",
    "    \n",
    "    \n",
    "    #relationship\n",
    "    df.drop(['relationship'], axis=1)\n",
    "    \n",
    "    #race\n",
    "    \n",
    "    #sex\n",
    "    \n",
    "    #workclass\n",
    "    \n",
    "    \n",
    "    #occpation\n",
    "    \n",
    "    #native.country\n",
    "    df.drop(['native.country'], axis=1)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f90feb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing(train)\n",
    "preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90f2051c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train.drop(['target'], axis=1)\n",
    "target_df = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b36eadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age', 'workclass', 'education', 'education.num', 'marital.status', 'occupation', 'relationship', 'race', 'sex']\n",
      "[ 1  2  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "cat_features = []\n",
    "\n",
    "def column_index(df, cat_features):\n",
    "    cols = df.columns.values\n",
    "    sidx = np.argsort(cols)\n",
    "    return sidx[np.searchsorted(cols, cat_features, sorter=sidx)]\n",
    "\n",
    "for col in train_df.columns:\n",
    "    target = train_df[col]\n",
    "    if target.nunique() <= 20:\n",
    "        cat_features.append(col)\n",
    "    cat_features_idx = column_index(train_df, cat_features)\n",
    "print(cat_features)\n",
    "print(cat_features_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "id": "aa63f814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.031626\n",
      "0:\tlearn: 0.6626343\ttotal: 47.7ms\tremaining: 47.7s\n",
      "100:\tlearn: 0.2794633\ttotal: 5.73s\tremaining: 51s\n",
      "200:\tlearn: 0.2644652\ttotal: 11.6s\tremaining: 46.3s\n",
      "300:\tlearn: 0.2544592\ttotal: 17s\tremaining: 39.6s\n",
      "400:\tlearn: 0.2453992\ttotal: 22.7s\tremaining: 33.9s\n",
      "500:\tlearn: 0.2388675\ttotal: 28.1s\tremaining: 27.9s\n",
      "600:\tlearn: 0.2328611\ttotal: 33.4s\tremaining: 22.2s\n",
      "700:\tlearn: 0.2278318\ttotal: 38.9s\tremaining: 16.6s\n",
      "800:\tlearn: 0.2232068\ttotal: 44.3s\tremaining: 11s\n",
      "900:\tlearn: 0.2189459\ttotal: 49.9s\tremaining: 5.48s\n",
      "999:\tlearn: 0.2146759\ttotal: 55.6s\tremaining: 0us\n",
      "0.8794100636205899\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_df, target_df, test_size=0.2, stratify=target_df, random_state=0)\n",
    "\n",
    "cb = CatBoostClassifier()\n",
    "\n",
    "cb.fit(X_train,y_train, cat_features=cat_features, verbose=100)\n",
    "\n",
    "pred = cb.predict(X_test)\n",
    "print(accuracy_score(pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "id": "1a2f70e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 10.300664357707452,\n",
       " 'workclass': 11.15523870764783,\n",
       " 'fnlwgt': 5.009930338530053,\n",
       " 'education': 4.584492290267686,\n",
       " 'education.num': 5.6604563121350004,\n",
       " 'marital.status': 7.525777594971174,\n",
       " 'occupation': 9.261079890737346,\n",
       " 'relationship': 14.575559008658356,\n",
       " 'race': 1.6851195084954749,\n",
       " 'sex': 1.7066850791084716,\n",
       " 'capital.gain': 12.995901104327807,\n",
       " 'capital.loss': 6.247774235661497,\n",
       " 'hours.per.week': 9.291321571751823}"
      ]
     },
     "execution_count": 1167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances = {}\n",
    "for i in range(0,len(train_df.columns)):\n",
    "    feature_importances[train_df.columns[i]]=cb.get_feature_importance()[i]\n",
    "\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "id": "1dc0249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    param = {\n",
    "      \"random_state\":0,\n",
    "      \"objective\": trial.suggest_categorical(\"objective\", [\"Logloss\", \"CrossEntropy\"]),\n",
    "      \"colsample_bylevel\": trial.suggest_float(\"colsample_bylevel\", 0.01, 0.1),\n",
    "      \"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "      \"bootstrap_type\": trial.suggest_categorical(\"bootstrap_type\", [\"Bayesian\", \"Bernoulli\", \"MVS\"]),\n",
    "      'learning_rate' : trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "      \"n_estimators\":trial.suggest_int(\"n_estimators\", 1000, 10000),\n",
    "      \"max_depth\":trial.suggest_int(\"max_depth\", 4, 16),\n",
    "      'random_strength' :trial.suggest_int('random_strength', 0, 100),\n",
    "      \"l2_leaf_reg\":trial.suggest_float(\"l2_leaf_reg\",1e-8,3e-5),\n",
    "      \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "      \"max_bin\": trial.suggest_int(\"max_bin\", 200, 500),\n",
    "      'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "      }\n",
    "\n",
    "    if param[\"bootstrap_type\"] == \"Bayesian\":\n",
    "        param[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    elif param[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "        param[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1)\n",
    "\n",
    "    model = CatBoostClassifier(**param)\n",
    "\n",
    "    model.fit(X_train, y_train, eval_set=[(X_test, y_test)], verbose=0, cat_features=cat_features)\n",
    "\n",
    "    preds = model.predict(X_test)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(y_test, pred_labels)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71dfcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "id": "d68ebfb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.8791208791208791\n",
      "  Params: \n",
      "    objective: CrossEntropy\n",
      "    colsample_bylevel: 0.0509613126112151\n",
      "    boosting_type: Ordered\n",
      "    bootstrap_type: MVS\n",
      "    learning_rate: 0.052873040650087154\n",
      "    n_estimators: 8448\n",
      "    max_depth: 12\n",
      "    random_strength: 57\n",
      "    l2_leaf_reg: 1.3757339190257113e-05\n",
      "    min_child_samples: 66\n",
      "    max_bin: 292\n",
      "    od_type: IncToDec\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "id": "9c02f113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "cat_models={}\n",
    "    \n",
    "folds=StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "outcomes=[]\n",
    "\n",
    "for seed in [0]:\n",
    "    for n_fold, (train_index, val_index) in enumerate(folds.split(train_df, target_df)):\n",
    "        print(f'===================================={n_fold+1}============================================')\n",
    "\n",
    "        X_train, X_val = train_df.iloc[train_index], train_df.iloc[val_index]\n",
    "        y_train, y_val = target_df.iloc[train_index], target_df.iloc[val_index]\n",
    "\n",
    "        # early_stopping 50에서 가장 좋은 점수를 내는 learning_rate를 활용\n",
    "        cat = CatBoostClassifier(**trial.params)\n",
    "        cat.fit(X_train, y_train,\n",
    "              eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "              cat_features=cat_features,\n",
    "              verbose=100)\n",
    "\n",
    "        cat_models[n_fold] = cat\n",
    "\n",
    "        # val 데이터 예측\n",
    "        predictions = cat.predict(X_val)\n",
    "        \n",
    "        accuracy=accuracy_score(y_val, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(f\"FOLD {n_fold+1} : accuracy:{accuracy}\")\n",
    "\n",
    "        print(f'================================================================================\\n\\n')\n",
    "\n",
    "# 저장된 val 데이터 예측 logloss 값의 평균 값으로 성능을 비교\n",
    "mean_outcome=np.mean(outcomes)\n",
    "print(\"Mean:{}\".format(mean_outcome))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "303.825px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
